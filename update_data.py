import time
import os
import re
import pandas as pd
import requests
import json
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import Select
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# --- è¨­å®š ---
DATA_DIR = "data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

def get_taiwan_date():
    return (datetime.utcnow() + timedelta(hours=8)).strftime('%Y-%m-%d')

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)

def save_to_csv(etf_code, new_df):
    file_path = f"{DATA_DIR}/{etf_code}_history.csv"
    today_str = get_taiwan_date()
    
    if isinstance(new_df, list): new_df = pd.DataFrame(new_df)
    if 'Date' not in new_df.columns: new_df.insert(0, 'Date', today_str)
    
    # å¼·åˆ¶è½‰å‹æ¬Šé‡ç‚ºæ•¸å­—
    new_df['æ¬Šé‡'] = pd.to_numeric(new_df['æ¬Šé‡'], errors='coerce').fillna(0)
    
    if os.path.exists(file_path):
        old_df = pd.read_csv(file_path, dtype=str)
        old_df = old_df[old_df['Date'] != today_str]
        final_df = pd.concat([old_df, new_df], ignore_index=True)
    else:
        final_df = new_df
        
    final_df.to_csv(file_path, index=False, encoding='utf-8-sig')
    print(f"âœ… [{etf_code}] æˆåŠŸå„²å­˜ {len(new_df)} ç­†è³‡æ–™ï¼")
    return len(new_df)

def clean_column_name(col):
    if isinstance(col, tuple): col = "".join(str(c) for c in col)
    return str(col).strip().replace(" ", "").replace("\n", "")

def clean_cell_data(val):
    """å¼·åŠ›æ¸…æ´—ï¼šè§£æ±ºç–Šå­—ã€ç©ºç™½ã€æ›è¡Œ"""
    s = str(val).strip()
    # è™•ç†ä¸­é–“æœ‰ç©ºç™½çš„ç–Šå­— ("2330 2330")
    parts = s.split()
    if len(parts) == 2 and parts[0] == parts[1]:
        return parts[0]
    # è™•ç†ç„¡ç©ºç™½ç–Šå­— ("23302330")
    if len(s) > 1 and len(s) % 2 == 0:
        mid = len(s) // 2
        if s[:mid] == s[mid:]:
            return s[:mid]
    return s

# ==========================================
# 00981A: çµ±ä¸€å°è‚¡å¢é•· (é¸å–®é¸å–ç‰ˆ)
# ==========================================
def update_00981A():
    TARGET_NAME = "çµ±ä¸€å°è‚¡å¢é•·ä¸»å‹•å¼ETFåŸºé‡‘" 
    print(f"\nğŸš€ [00981A] å•Ÿå‹•çˆ¬èŸ²ï¼šçµ±ä¸€æŠ•ä¿¡...")
    url = "https://www.ezmoney.com.tw/ETF/Transaction/PCF"
    driver = get_driver()
    count = 0
    try:
        driver.get(url)
        time.sleep(5)
        # åˆ‡æ›é¸å–®
        print(f"ğŸ‘† å°‹æ‰¾åŸºé‡‘ï¼š{TARGET_NAME}...")
        found = False
        try:
            selects = driver.find_elements(By.TAG_NAME, "select")
            for el in selects:
                try:
                    select = Select(el)
                    for opt in select.options:
                        if "å°è‚¡å¢é•·" in opt.text and "ä¸»å‹•" in opt.text:
                            print(f"ğŸ¯ æ‰¾åˆ°ç›®æ¨™ï¼š{opt.text}")
                            select.select_by_visible_text(opt.text)
                            found = True
                            time.sleep(5)
                            break
                except: pass
                if found: break
            if not found: print("âš ï¸ è­¦å‘Šï¼šé¸å–®ä¸­æ‰¾ä¸åˆ°è©²åŸºé‡‘ï¼Œå°‡æŠ“å–é è¨­å€¼ã€‚")
        except: pass

        html = driver.page_source
        dfs = pd.read_html(html)
        target_df = pd.DataFrame()
        for df in dfs:
            df.columns = [clean_column_name(c) for c in df.columns]
            cols = "".join(df.columns)
            if ("ä»£è™Ÿ" in cols or "åç¨±" in cols) and ("æ¬Šé‡" in cols or "æ¯”é‡" in cols):
                rename_map = {}
                for c in df.columns:
                    if "ä»£è™Ÿ" in c: rename_map[c] = "è‚¡ç¥¨ä»£è™Ÿ"
                    elif "åç¨±" in c: rename_map[c] = "è‚¡ç¥¨åç¨±"
                    elif "è‚¡æ•¸" in c: rename_map[c] = "æŒæœ‰è‚¡æ•¸"
                    elif "æ¬Šé‡" in c or "æ¯”é‡" in c: rename_map[c] = "æ¬Šé‡"
                df = df.rename(columns=rename_map)
                if "è‚¡ç¥¨åç¨±" in df.columns and "æ¬Šé‡" in df.columns:
                    target_df = df.copy()
                    if "è‚¡ç¥¨ä»£è™Ÿ" not in target_df.columns: target_df["è‚¡ç¥¨ä»£è™Ÿ"] = target_df["è‚¡ç¥¨åç¨±"]
                    if "æŒæœ‰è‚¡æ•¸" not in target_df.columns: target_df["æŒæœ‰è‚¡æ•¸"] = 0
                    break
        if not target_df.empty:
            target_df = target_df[['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']]
            for col in target_df.columns: target_df[col] = target_df[col].apply(clean_cell_data)
            target_df['æŒæœ‰è‚¡æ•¸'] = target_df['æŒæœ‰è‚¡æ•¸'].astype(str).str.replace(',', '').str.replace('--', '0')
            target_df['æ¬Šé‡'] = target_df['æ¬Šé‡'].astype(str).str.replace('%', '')
            count = save_to_csv("00981A", target_df)
        else: print("âŒ [00981A] æ‰¾ä¸åˆ°è¡¨æ ¼")
    except Exception as e: print(f"âŒ [00981A] éŒ¯èª¤: {e}")
    finally: driver.quit()
    return count

# ==========================================
# 00980A: é‡æ‘è‡ºç£æ™ºæ…§å„ªé¸ (V12 æŸ¥çœ‹æ›´å¤šä¿®æ­£ç‰ˆ)
# ==========================================
def update_00980A():
    print(f"\nğŸš€ [00980A] å•Ÿå‹•çˆ¬èŸ²ï¼šé‡æ‘æŠ•ä¿¡ (00980A)...")
    url = "https://www.nomurafunds.com.tw/ETFWEB/product-description?fundNo=00980A"
    driver = get_driver()
    count = 0
    
    try:
        driver.get(url)
        time.sleep(8)
        
        # 1. æš´åŠ›æ²å‹•å–šé†’
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
        time.sleep(1)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
        
        # 2. åˆ‡æ›åˆ†é  (æŒè‚¡æ¬Šé‡)
        try:
            tabs = driver.find_elements(By.XPATH, "//*[contains(text(),'æŒè‚¡') or contains(text(),'æˆåˆ†')]")
            for tab in tabs:
                if tab.is_displayed():
                    driver.execute_script("arguments[0].click();", tab)
                    time.sleep(2)
                    break
        except: pass

        # 3. â˜…â˜…â˜… é—œéµä¿®æ­£ï¼šé‡å°ã€ŒæŸ¥çœ‹æ›´å¤šã€æ–‡å­—é»æ“Š â˜…â˜…â˜…
        print("ğŸ‘† å°‹æ‰¾ã€ŒæŸ¥çœ‹æ›´å¤šã€æŒ‰éˆ•...")
        try:
            # é‡æ‘çš„æŒ‰éˆ•å¸¸å¸¸å°±æ˜¯è¡¨æ ¼çš„æœ€å¾Œä¸€åˆ—ï¼Œè£¡é¢å¯«è‘—ã€ŒæŸ¥çœ‹æ›´å¤šã€
            # æˆ‘å€‘ç›´æ¥æ‰¾åŒ…å«é€™å››å€‹å­—çš„å…ƒç´ 
            xpath = "//*[contains(text(),'æŸ¥çœ‹æ›´å¤š') or contains(text(),'é¡¯ç¤ºå…¨éƒ¨')]"
            elements = driver.find_elements(By.XPATH, xpath)
            for el in elements:
                if el.is_displayed():
                    print(f"   ğŸ¯ é»æ“Šï¼š{el.text}")
                    driver.execute_script("arguments[0].click();", el)
                    time.sleep(3) # é»å®Œè¦ç­‰ä¸€ä¸‹
                    break
        except Exception as e:
            print(f"âš ï¸ é»æ“Šå¤±æ•—: {e}")

        # 4. æŠ“å–è¡¨æ ¼
        print("â³ è®€å–è¡¨æ ¼ä¸­...")
        best_df = pd.DataFrame()
        # å˜—è©¦å¤šæ¬¡ï¼Œç­‰å¾…è³‡æ–™å±•é–‹
        for _ in range(10):
            try:
                html = driver.page_source
                dfs = pd.read_html(html)
                current_best = pd.DataFrame()
                max_rows = 0
                for df in dfs:
                    df.columns = [clean_column_name(c) for c in df.columns]
                    cols = "".join(df.columns)
                    if ("åç¨±" in cols or "ä»£è™Ÿ" in cols) and ("æ¬Šé‡" in cols or "æ¯”ä¾‹" in cols):
                        # â˜…â˜…â˜… éæ¿¾æ‰ã€ŒæŸ¥çœ‹æ›´å¤šã€é€™ç¨®åƒåœ¾è¡Œ â˜…â˜…â˜…
                        # å¦‚æœæŸä¸€è¡Œçš„ã€Œè‚¡ç¥¨åç¨±ã€åŒ…å«ã€ŒæŸ¥çœ‹æ›´å¤šã€ï¼Œå°±ä¸è¦ç®—å®ƒ
                        if 'è‚¡ç¥¨åç¨±' in df.columns:
                            df = df[~df['è‚¡ç¥¨åç¨±'].astype(str).str.contains('æŸ¥çœ‹æ›´å¤š|æ›´å¤š')]
                        
                        if len(df) > max_rows:
                            max_rows = len(df)
                            current_best = df.copy()
                
                print(f"   ç›®å‰æœ€å¤§è¡Œæ•¸: {max_rows}")
                if max_rows > 15: # åªè¦å¤§æ–¼ 15 ç­†å°±ç•¶ä½œæˆåŠŸ
                    best_df = current_best
                    break
                if max_rows > 0: best_df = current_best
                time.sleep(2)
            except: pass

        if not best_df.empty:
            rename_map = {}
            for c in best_df.columns:
                if "ä»£è™Ÿ" in c: rename_map[c] = "è‚¡ç¥¨ä»£è™Ÿ"
                elif "åç¨±" in c: rename_map[c] = "è‚¡ç¥¨åç¨±"
                elif "è‚¡æ•¸" in c: rename_map[c] = "æŒæœ‰è‚¡æ•¸"
                elif "æ¬Šé‡" in c or "æ¯”ä¾‹" in c: rename_map[c] = "æ¬Šé‡"
            
            best_df = best_df.rename(columns=rename_map)
            
            if "è‚¡ç¥¨åç¨±" in best_df.columns:
                if "è‚¡ç¥¨ä»£è™Ÿ" not in best_df.columns: best_df["è‚¡ç¥¨ä»£è™Ÿ"] = best_df["è‚¡ç¥¨åç¨±"]
                if "æŒæœ‰è‚¡æ•¸" not in best_df.columns: best_df["æŒæœ‰è‚¡æ•¸"] = 0
                
                best_df = best_df[['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']]
                
                # æœ€å¾Œå†æ¸…æ´—ä¸€æ¬¡ï¼Œç¢ºä¿æ²’æœ‰ã€ŒæŸ¥çœ‹æ›´å¤šã€æ®˜ç•™
                best_df = best_df[~best_df['è‚¡ç¥¨åç¨±'].astype(str).str.contains('æŸ¥çœ‹æ›´å¤š')]
                best_df = best_df[~best_df['è‚¡ç¥¨ä»£è™Ÿ'].astype(str).str.contains('æŸ¥çœ‹æ›´å¤š')]

                # æ¸…æ´—æ•¸æ“š
                for col in best_df.columns: best_df[col] = best_df[col].apply(clean_cell_data)
                best_df['æ¬Šé‡'] = best_df['æ¬Šé‡'].astype(str).str.replace('%', '')
                
                count = save_to_csv("00980A", best_df)
            else: print("âŒ [00980A] æ¬„ä½éŒ¯èª¤")
        else:
            print("âŒ [00980A] æ‰¾ä¸åˆ°è¡¨æ ¼")

    except Exception as e:
        print(f"âŒ [00980A] éŒ¯èª¤: {e}")
    finally:
        driver.quit()
    return count

# ==========================================
# 00991A: å¾©è¯æœªä¾†50 (V21 æ­»çºçˆ›æ‰“é‡è©¦ç‰ˆ)
# ==========================================
def update_00991A():
    TARGET_NAME = "å¾©è¯æœªä¾†50"
    print(f"\nğŸš€ [00991A] å•Ÿå‹•çˆ¬èŸ²ï¼šå¾©è¯æŠ•ä¿¡ ({TARGET_NAME})...")
    url = "https://www.fhtrust.com.tw/ETF/etf_detail/ETF23"
    
    # å…§éƒ¨å‡½å¼ï¼šåŸ·è¡Œä¸€æ¬¡å®Œæ•´çš„æŠ“å–æµç¨‹
    def run_scrape_attempt(driver):
        try:
            driver.get(url)
            time.sleep(10) # åŸºç¤ç­‰å¾…
            
            # 1. å–šé†’é é¢
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
            time.sleep(2)
            
            # 2. å®šä½å€å¡Š
            try:
                xpath = "//*[contains(text(),'æŒè‚¡æ¬Šé‡') or contains(text(),'åŸºé‡‘æŒè‚¡') or @id='stockhold']"
                target = driver.find_element(By.XPATH, xpath)
                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", target)
                time.sleep(2)
            except: pass

            # 3. å°‹æ‰¾ä¸¦é»æ“ŠæŒ‰éˆ• (å˜—è©¦å¤šç¨®é¸æ“‡å™¨)
            print("   ğŸ‘† å°‹æ‰¾å±•é–‹æŒ‰éˆ•...")
            try:
                # æ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„æŒ‰éˆ•
                buttons = driver.find_elements(By.XPATH, "//*[contains(text(),'æ›´å¤š') or contains(text(),'å±•é–‹') or contains(@class, 'more')]")
                
                clicked = False
                for btn in buttons:
                    if btn.is_displayed():
                        # ä½¿ç”¨ JS å¼·åˆ¶é»æ“Š (ç©¿é€é®æ“‹)
                        driver.execute_script("arguments[0].click();", btn)
                        clicked = True
                        print(f"   ğŸ¯ é»æ“Šäº†: {btn.text}")
                        time.sleep(1) # é»ä¸€ä¸‹ç­‰ä¸€ä¸‹
                
                if clicked:
                    print("   â³ é»æ“Šå®Œæˆï¼Œç­‰å¾…è³‡æ–™è¼‰å…¥ (10ç§’)...")
                    time.sleep(10)
                else:
                    print("   âš ï¸ æ²’æ‰¾åˆ°æŒ‰éˆ•ï¼Œå¯èƒ½å·²å±•é–‹æˆ–è¢«é®æ“‹")
            except Exception as e:
                print(f"   âš ï¸ é»æ“ŠéŒ¯èª¤: {e}")

            # 4. æŠ“å–è³‡æ–™
            best_df = pd.DataFrame()
            html = driver.page_source
            dfs = pd.read_html(html)
            
            for df in dfs:
                df.columns = [clean_column_name(c) for c in df.columns]
                cols = "".join(df.columns)
                if ("åç¨±" in cols or "ä»£è™Ÿ" in cols) and ("æ¬Šé‡" in cols or "æ¯”ä¾‹" in cols):
                    if len(df) > len(best_df):
                        best_df = df.copy()
            
            return best_df

        except Exception as e:
            print(f"   âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
            return pd.DataFrame()

    # --- ä¸»æµç¨‹ï¼šæœ€å¤šå˜—è©¦ 3 æ¬¡ ---
    driver = get_driver()
    final_df = pd.DataFrame()
    
    for attempt in range(1, 4): # å˜—è©¦ç¬¬ 1, 2, 3 æ¬¡
        print(f"ğŸ”„ ç¬¬ {attempt} æ¬¡å˜—è©¦æŠ“å–...")
        current_df = run_scrape_attempt(driver)
        
        if not current_df.empty and len(current_df) > 20:
            print(f"ğŸŒŸ æˆåŠŸï¼æŠ“åˆ° {len(current_df)} ç­†è³‡æ–™ï¼")
            final_df = current_df
            break # æˆåŠŸå°±è·³å‡ºè¿´åœˆ
        else:
            print(f"âš ï¸ ç¬¬ {attempt} æ¬¡å¤±æ•— (åªæŠ“åˆ° {len(current_df)} ç­†)ï¼Œæº–å‚™é‡è©¦...")
            driver.delete_all_cookies() # æ¸…é™¤ Cookie é¿å…è¢«èˆŠç‹€æ…‹å¡ä½
            time.sleep(5) # ä¼‘æ¯ä¸€ä¸‹å†è©¦

    driver.quit()

    # --- çµç®—èˆ‡å­˜æª” ---
    if not final_df.empty and len(final_df) > 20:
        rename_map = {}
        for c in final_df.columns:
            if "ä»£è™Ÿ" in c: rename_map[c] = "è‚¡ç¥¨ä»£è™Ÿ"
            elif "åç¨±" in c: rename_map[c] = "è‚¡ç¥¨åç¨±"
            elif "è‚¡æ•¸" in c: rename_map[c] = "æŒæœ‰è‚¡æ•¸"
            elif "æ¬Šé‡" in c: rename_map[c] = "æ¬Šé‡"
        
        final_df = final_df.rename(columns=rename_map)
        if "è‚¡ç¥¨åç¨±" in final_df.columns:
            if "è‚¡ç¥¨ä»£è™Ÿ" not in final_df.columns: final_df["è‚¡ç¥¨ä»£è™Ÿ"] = final_df["è‚¡ç¥¨åç¨±"]
            if "æŒæœ‰è‚¡æ•¸" not in final_df.columns: final_df["æŒæœ‰è‚¡æ•¸"] = 0
            
            final_df = final_df[['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']]
            # æ¸…æ´—
            for col in final_df.columns: final_df[col] = final_df[col].apply(clean_cell_data)
            final_df['æ¬Šé‡'] = final_df['æ¬Šé‡'].astype(str).str.replace('%', '')
            
            return save_to_csv("00991A", final_df)
    
    print("âŒ [00991A] ä¸‰æ¬¡å˜—è©¦çš†å¤±æ•—ï¼Œæ”¾æ£„æ›´æ–° (ä¿ç•™èˆŠè³‡æ–™ä»¥ç­–å®‰å…¨)")
    return 0
# ==========================================
# Discord æ¨æ’­
# ==========================================
def send_discord_notify(message):
    webhook_url = os.environ.get("DISCORD_WEBHOOK")
    if not webhook_url: return
    data = {"username": "ğŸ¦ ETF æˆ°æƒ…å®¤", "content": message}
    try: requests.post(webhook_url, json=data)
    except: pass

if __name__ == "__main__":
    print("=== é–‹å§‹è‡ªå‹•æ›´æ–° ===")
    c1 = update_00981A()
    c2 = update_00991A()
    c3 = update_00980A()
    
    today = get_taiwan_date()
    msg = f"ğŸ“¢ **{today} ETF æŒè‚¡æ›´æ–°å ±å‘Š**\n"
    msg += f"âœ… **00981A (çµ±ä¸€)**: æ›´æ–° {c1} ç­†\n" if c1 > 0 else f"âš ï¸ **00981A**: å¤±æ•—\n"
    msg += f"âœ… **00991A (å¾©è¯)**: æ›´æ–° {c2} ç­†\n" if c2 > 0 else f"âš ï¸ **00991A**: å¤±æ•—\n"
    msg += f"âœ… **00980A (é‡æ‘)**: æ›´æ–° {c3} ç­†\n" if c3 > 0 else f"âš ï¸ **00980A**: å¤±æ•—\n"
    
    send_discord_notify(msg)
    print("=== æ›´æ–°çµæŸ ===")
