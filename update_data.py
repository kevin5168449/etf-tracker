import time
import os
import pandas as pd
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager

# --- è¨­å®š ---
DATA_DIR = "data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

def get_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    # å½è£ User-Agent
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
    
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=chrome_options)

def save_to_csv(etf_code, new_df):
    file_path = f"{DATA_DIR}/{etf_code}_history.csv"
    today_str = datetime.now().strftime('%Y-%m-%d')
    new_df.insert(0, 'Date', today_str)
    
    if os.path.exists(file_path):
        old_df = pd.read_csv(file_path, dtype=str)
        old_df = old_df[old_df['Date'] != today_str]
        final_df = pd.concat([old_df, new_df], ignore_index=True)
    else:
        final_df = new_df
        
    final_df.to_csv(file_path, index=False, encoding='utf-8-sig')
    print(f"âœ… [{etf_code}] æˆåŠŸå„²å­˜ {len(new_df)} ç­†è³‡æ–™ï¼")

def clean_columns(df):
    """å°‡å¤šå±¤ç´¢å¼•æ¬„ä½(Tuple)å£“æ‰ç‚ºå–®ä¸€å­—ä¸²ï¼Œä¸¦ç§»é™¤ç©ºç™½"""
    new_columns = []
    for col in df.columns:
        if isinstance(col, tuple):
            # å¦‚æœæ˜¯å¤šå±¤æ¨™é¡Œ (tuple)ï¼ŒæŠŠå®ƒå€‘æ¥èµ·ä¾†
            col_str = "".join(str(c) for c in col)
        else:
            col_str = str(col)
        new_columns.append(col_str.strip().replace(" ", "").replace("\n", ""))
    df.columns = new_columns
    return df

# ==========================================
# 00981A: çµ±ä¸€æŠ•ä¿¡ (ä¿®å¾© tuple éŒ¯èª¤)
# ==========================================
def update_00981A():
    print("\nğŸš€ [00981A] å•Ÿå‹•çˆ¬èŸ²ï¼šçµ±ä¸€æŠ•ä¿¡...")
    url = "https://www.ezmoney.com.tw/ETF/Transaction/PCF"
    driver = get_driver()
    
    try:
        driver.get(url)
        try:
            # ç­‰å¾…è¡¨æ ¼å‡ºç¾
            WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.TAG_NAME, "table")))
        except:
            print("âš ï¸ ç­‰å¾…è¶…æ™‚")

        html = driver.page_source
        dfs = pd.read_html(html)
        print(f"ğŸ” ç¶²é ä¸­ç™¼ç¾ {len(dfs)} å€‹è¡¨æ ¼")
        
        target_df = pd.DataFrame()
        
        for i, df in enumerate(dfs):
            # â˜…â˜…â˜… é—œéµä¿®å¾©ï¼šå…ˆè™•ç†æ¬„ä½æ ¼å¼ï¼Œé¿å… tuple å ±éŒ¯ â˜…â˜…â˜…
            df = clean_columns(df)
            cols = "".join(df.columns)
            
            if "ä»£è™Ÿ" in cols and ("æ¬Šé‡" in cols or "æ¯”é‡" in cols):
                print(f"ğŸ¯ é–å®šç¬¬ {i+1} å€‹è¡¨æ ¼")
                
                # æ¨¡ç³Šå°æ‡‰
                rename_map = {}
                for c in df.columns:
                    if "ä»£è™Ÿ" in c: rename_map[c] = "è‚¡ç¥¨ä»£è™Ÿ"
                    elif "åç¨±" in c: rename_map[c] = "è‚¡ç¥¨åç¨±"
                    elif "è‚¡æ•¸" in c: rename_map[c] = "æŒæœ‰è‚¡æ•¸"
                    elif "æ¬Šé‡" in c or "æ¯”é‡" in c: rename_map[c] = "æ¬Šé‡"
                
                df = df.rename(columns=rename_map)
                
                if "è‚¡ç¥¨ä»£è™Ÿ" in df.columns and "æ¬Šé‡" in df.columns:
                    target_df = df.copy()
                    if "æŒæœ‰è‚¡æ•¸" not in target_df.columns: target_df["æŒæœ‰è‚¡æ•¸"] = 0
                    if "è‚¡ç¥¨åç¨±" not in target_df.columns: target_df["è‚¡ç¥¨åç¨±"] = target_df["è‚¡ç¥¨ä»£è™Ÿ"]
                    break
        
        if not target_df.empty:
            target_df = target_df[['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']]
            target_df['æŒæœ‰è‚¡æ•¸'] = target_df['æŒæœ‰è‚¡æ•¸'].astype(str).str.replace(',', '').str.replace('--', '0')
            target_df['æ¬Šé‡'] = target_df['æ¬Šé‡'].astype(str).str.replace('%', '')
            save_to_csv("00981A", target_df)
        else:
            print("âŒ [00981A] æ‰¾ä¸åˆ°æˆåˆ†è‚¡è¡¨æ ¼ï¼Œè«‹æª¢æŸ¥ Logã€‚")

    except Exception as e:
        print(f"âŒ [00981A] ç³»çµ±éŒ¯èª¤: {e}")
    finally:
        driver.quit()

# ==========================================
# 00991A: å¾©è¯æŠ•ä¿¡ (å¢åŠ ç­‰å¾…èˆ‡é™¤éŒ¯ Log)
# ==========================================
def update_00991A():
    print("\nğŸš€ [00991A] å•Ÿå‹•çˆ¬èŸ²ï¼šå¾©è¯æŠ•ä¿¡...")
    url = "https://www.fhtrust.com.tw/ETF/etf_detail/ETF23#stockhold"
    driver = get_driver()
    
    try:
        driver.get(url)
        time.sleep(5)
        
        print("ğŸ‘† å°‹æ‰¾å±•é–‹æŒ‰éˆ•...")
        try:
            js_script = """
            var btns = document.querySelectorAll('a, button, div');
            for (var i = 0; i < btns.length; i++) {
                if (btns[i].innerText.includes('æ›´å¤š') || btns[i].innerText.includes('å±•é–‹')) {
                    btns[i].click();
                    return true;
                }
            }
            return false;
            """
            result = driver.execute_script(js_script)
            if result:
                print("âœ… JS é»æ“ŠæˆåŠŸ")
            else:
                print("âš ï¸ JS æ²’æ‰¾åˆ°æŒ‰éˆ•ï¼Œå˜—è©¦æ»¾å‹•...")
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            
            # â˜…â˜…â˜… å¢åŠ ç­‰å¾…æ™‚é–“ï¼Œè®“è¡¨æ ¼è¼‰å…¥ â˜…â˜…â˜…
            time.sleep(8) 
        except:
            print("âš ï¸ é»æ“Šæ“ä½œç•¥é")

        html = driver.page_source
        dfs = pd.read_html(html)
        print(f"ğŸ” å¾©è¯ç¶²é ç™¼ç¾ {len(dfs)} å€‹è¡¨æ ¼")

        target_df = pd.DataFrame()
        
        for i, df in enumerate(dfs):
            # â˜…â˜…â˜… é—œéµä¿®å¾©ï¼šåŒæ¨£å…ˆæ¸…ç†æ¬„ä½ â˜…â˜…â˜…
            df = clean_columns(df)
            cols = "".join(df.columns)
            
            # â˜…â˜…â˜… é—œéµé™¤éŒ¯ï¼šæŠŠçœ‹åˆ°çš„æ‰€æœ‰è¡¨æ ¼æ¬„ä½å°å‡ºä¾† â˜…â˜…â˜…
            print(f"   ğŸ“‹ è¡¨æ ¼ {i} æ¬„ä½ (å‰5): {df.columns.tolist()[:5]}...") 

            if ("åç¨±" in cols or "ä»£è™Ÿ" in cols) and ("æ¬Šé‡" in cols or "æ¯”ä¾‹" in cols):
                print(f"ğŸ¯ é–å®šè¡¨æ ¼ {i}")
                
                rename_map = {}
                for c in df.columns:
                    if "ä»£è™Ÿ" in c: rename_map[c] = "è‚¡ç¥¨ä»£è™Ÿ"
                    elif "åç¨±" in c: rename_map[c] = "è‚¡ç¥¨åç¨±"
                    elif "è‚¡æ•¸" in c or "åº«å­˜" in c: rename_map[c] = "æŒæœ‰è‚¡æ•¸"
                    elif "æ¬Šé‡" in c or "æ¯”ä¾‹" in c or "æ¯”é‡" in c: rename_map[c] = "æ¬Šé‡"
                
                df = df.rename(columns=rename_map)
                
                if "è‚¡ç¥¨åç¨±" in df.columns and "æ¬Šé‡" in df.columns:
                    if "è‚¡ç¥¨ä»£è™Ÿ" not in df.columns: df["è‚¡ç¥¨ä»£è™Ÿ"] = df["è‚¡ç¥¨åç¨±"]
                    if "æŒæœ‰è‚¡æ•¸" not in df.columns: df["æŒæœ‰è‚¡æ•¸"] = 0
                    target_df = df.copy()
                    break
        
        if not target_df.empty:
            target_df = target_df[['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']]
            target_df['æ¬Šé‡'] = target_df['æ¬Šé‡'].astype(str).str.replace('%', '')
            save_to_csv("00991A", target_df)
        else:
            print("âŒ [00991A] æ‰¾ä¸åˆ°è¡¨æ ¼ (è«‹æŸ¥çœ‹ä¸Šæ–¹ Log å°å‡ºçš„æ¬„ä½)")

    except Exception as e:
        print(f"âŒ [00991A] éŒ¯èª¤: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    update_00981A()
    update_00991A()
