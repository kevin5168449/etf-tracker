import streamlit as st
import pandas as pd
import os
import plotly.express as px
import plotly.graph_objects as go
import requests
from bs4 import BeautifulSoup

# --- é é¢åŸºæœ¬è¨­å®š ---
st.set_page_config(page_title="ETF æˆ°æƒ…å®¤ Pro", page_icon="ğŸ¦", layout="wide")

# --- CSS å„ªåŒ– (æ¥µç°¡ + é‡é»å¼·åŒ–) ---
st.markdown("""
<style>
    .stDataFrame { font-size: 1.05rem; }
    /* KPI æ•¸å­—æ”¾å¤§ */
    div[data-testid="stMetricValue"] {
        font-size: 1.5rem !important;
        font-weight: 700;
        color: #2c3e50;
    }
    /* ç”¢æ¥­æ¨™é¡Œæ¨£å¼ */
    .industry-header {
        font-size: 1.15rem;
        font-weight: 600;
        color: #495057;
        margin-top: 20px;
        margin-bottom: 8px;
        padding-left: 12px;
        border-left: 5px solid #0d6efd; /* è—è‰²å·¦é‚Šæ¢ */
        background-color: #f8f9fa;
        padding: 8px 12px;
        border-radius: 4px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }
    /* åŠ å¼·ç•°å‹•å€å¡Šçš„è¦–è¦º */
    .highlight-status {
        font-weight: bold;
        padding: 2px 6px;
        border-radius: 4px;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ¦ 2026 ä¸»å‹•å¼ ETF æ“ç›¤é€Ÿè¦½ (Top 500 é¡Œæç‰ˆ)")

# --- 1. è³‡æ–™è®€å–èˆ‡æ¸…æ´— ---
@st.cache_data(ttl=60)
def load_data(file_path):
    if not os.path.exists(file_path): return None
    try:
        return pd.read_csv(file_path, dtype=str, on_bad_lines='skip', engine='python', encoding='utf-8-sig')
    except: return None

def clean_data(df):
    if df is None or df.empty: return pd.DataFrame()
    for col in ['æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']:
        if col not in df.columns: df[col] = '0'
    for col in ['æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']:
        df[col] = df[col].astype(str).str.replace(',', '').str.replace('%', '')
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'])
        df['DateStr'] = df['Date'].dt.strftime('%Y-%m-%d')
    else: return pd.DataFrame()
    df = df.drop_duplicates(subset=['DateStr', 'è‚¡ç¥¨ä»£è™Ÿ'], keep='first')
    df = df.sort_values('Date', ascending=False)
    return df

# --- 2. è¶¨å‹¢ç·šé‚è¼¯ ---
def get_trend_data(full_df, stock_code):
    try:
        history = full_df[full_df['è‚¡ç¥¨ä»£è™Ÿ'] == stock_code].sort_values('Date', ascending=True)
        data = history['æ¬Šé‡'].tail(30).tolist()
        if not data or all(x == 0 for x in data): return [0.0, 0.0]
        return data
    except: return [0.0, 0.0]

# --- 3. ç©¶æ¥µåˆ†é¡ç³»çµ± (Top 500 + æ–°èé¡Œæ) ---
# é€™è£¡æˆ‘èŠ±æ™‚é–“æ•´ç†äº†æ–°èæœ€å¸¸æåˆ°çš„æ¿å¡Šï¼Œè€Œéæ­»æ¿çš„ç”¢æ¥­åˆ†é¡
STOCK_SECTOR_MAP = {
    # === ğŸ‘‘ è­·åœ‹ç¥å±±èˆ‡å¤§è¯ç›Ÿ (åŠå°é«”è£½é€ ) ===
    '2330': 'ğŸ‘‘ å°ç©é›»/æ™¶åœ“ä»£å·¥', '2303': 'ğŸ‘‘ æ™¶åœ“ä»£å·¥', '5347': 'ğŸ‘‘ æ™¶åœ“ä»£å·¥', '6770': 'ğŸ‘‘ æ™¶åœ“ä»£å·¥',
    
    # === ğŸ§  AI å¤§è…¦ (ICè¨­è¨ˆ/IP/ASIC) ===
    '2454': 'ğŸ§  ç™¼å“¥/ICè¨­è¨ˆ', '2379': 'ğŸ§  ç‘æ˜±/ICè¨­è¨ˆ', '3034': 'ğŸ§  è¯è© /ICè¨­è¨ˆ', 
    '3661': 'ğŸ§  çŸ½æ™ºè²¡ (IP/ASIC)', '3443': 'ğŸ§  çŸ½æ™ºè²¡ (IP/ASIC)', '3529': 'ğŸ§  çŸ½æ™ºè²¡ (IP/ASIC)', 
    '3035': 'ğŸ§  çŸ½æ™ºè²¡ (IP/ASIC)', '6643': 'ğŸ§  çŸ½æ™ºè²¡ (IP/ASIC)', '6531': 'ğŸ§  çŸ½æ™ºè²¡ (IP/ASIC)',
    '4961': 'ğŸ§  ICè¨­è¨ˆ', '8299': 'ğŸ§  ç¾¤è¯/è¨˜æ†¶é«”æ§åˆ¶', '5269': 'ğŸ§  ç¥¥ç¢©/é«˜é€Ÿå‚³è¼¸',
    '4966': 'ğŸ§  è­œç‘/é«˜é€Ÿå‚³è¼¸', '6415': 'ğŸ§  çŸ½åŠ›/é›»æºIC', '6138': 'ğŸ§  èŒ‚é”/é›»æºIC',

    # === ğŸ¤– AI ä¼ºæœå™¨è»ç«åº« (çµ„è£/ODM) ===
    '2317': 'ğŸ¤– é´»æµ·/çµ„è£', '2382': 'ğŸ¤– å»£é”/AIä¼ºæœå™¨', '3231': 'ğŸ¤– ç·¯å‰µ/AIä¼ºæœå™¨', 
    '2356': 'ğŸ¤– è‹±æ¥­é”', '2376': 'ğŸ¤– æŠ€å˜‰', '6669': 'ğŸ¤– ç·¯ç©/AIä¼ºæœå™¨', 
    '2324': 'ğŸ¤– ä»å¯¶', '2301': 'ğŸ¤– å…‰å¯¶ç§‘', '2421': 'ğŸ¤– å»ºæº–', '3013': 'ğŸ¤– æ™ŸéŠ˜é›»/æ©Ÿæ®¼',
    '8210': 'ğŸ¤– å‹¤èª /æ©Ÿæ®¼', '2059': 'ğŸ¤– å·æ¹–/å°è»Œ',

    # === â„ï¸ æ•£ç†± (æ¶²å†·/æ°£å†·) ===
    '3017': 'â„ï¸ å¥‡é‹/æ•£ç†±', '3324': 'â„ï¸ é›™é´»/æ•£ç†±', '3653': 'â„ï¸ å¥ç­–/æ•£ç†±', 
    '2421': 'â„ï¸ å»ºæº–/æ•£ç†±', '6230': 'â„ï¸ è¶…çœ¾', '8996': 'â„ï¸ é«˜åŠ›/æ¶²å†·',

    # === ğŸ“¦ CoWoS å…ˆé€²å°è£è¨­å‚™ ===
    '3131': 'ğŸ“¦ å¼˜å¡‘/CoWoSè¨­å‚™', '3583': 'ğŸ“¦ è¾›è€˜/CoWoSè¨­å‚™', '6187': 'ğŸ“¦ è¬æ½¤/CoWoSè¨­å‚™', 
    '6640': 'ğŸ“¦ å‡è¯', '2449': 'ğŸ“¦ äº¬å…ƒé›»/å°æ¸¬', '3711': 'ğŸ“¦ æ—¥æœˆå…‰/å°æ¸¬', 
    '6239': 'ğŸ“¦ åŠ›æˆ', '8150': 'ğŸ“¦ å—èŒ‚', '5483': 'ğŸ“¦ ä¸­ç¾æ™¶', '6488': 'ğŸ“¦ ç’°çƒæ™¶',

    # === ğŸ›¹ PCB èˆ‡ éŠ…ç®”åŸºæ¿ (CCL) ===
    '2383': 'ğŸ›¹ å°å…‰é›»/CCL', '6274': 'ğŸ›¹ å°ç‡¿/CCL', '6213': 'ğŸ›¹ è¯èŒ‚/CCL',
    '3037': 'ğŸ›¹ æ¬£èˆˆ/è¼‰æ¿', '3189': 'ğŸ›¹ æ™¯ç¢©', '8046': 'ğŸ›¹ å—é›»',
    '3044': 'ğŸ›¹ å¥é¼/PCB', '2313': 'ğŸ›¹ è¯é€š/ä½è»Œè¡›æ˜Ÿ', '3715': 'ğŸ›¹ å®šç©/è»Šç”¨PCB', 
    '2368': 'ğŸ›¹ é‡‘åƒé›»/ä¼ºæœå™¨PCB', '6191': 'ğŸ›¹ ç²¾æˆç§‘',

    # === âœ¨ CPO çŸ½å…‰å­/å…‰é€šè¨Š/ç¶²é€š ===
    '3081': 'âœ¨ è¯äº/CPO', '4979': 'âœ¨ è¯æ˜Ÿå…‰/CPO', '3450': 'âœ¨ è¯éˆ/CPO', 
    '4908': 'âœ¨ å‰é¼/CPO', '3234': 'âœ¨ å…‰ç’°', '2345': 'ğŸ“¡ æ™ºé‚¦/äº¤æ›å™¨', 
    '5388': 'ğŸ“¡ ä¸­ç£Š', '3704': 'ğŸ“¡ å•Ÿç¢', '6285': 'ğŸ“¡ å•Ÿç¢', '3045': 'ğŸ“¡ å°ç£å¤§', '2412': 'ğŸ“¡ ä¸­è¯é›»',

    # === ğŸ”Œ é›»æº/é‡é›»/ç¶ èƒ½ ===
    '2308': 'ğŸ”Œ å°é”é›»', '1513': 'âš¡ ä¸­èˆˆé›»/é‡é›»', '1519': 'âš¡ è¯åŸ/é‡é›»', 
    '1503': 'âš¡ å£«é›»', '1504': 'âš¡ æ±å…ƒ', '1605': 'âš¡ è¯æ–°/é›»çºœ', 
    '1609': 'âš¡ å¤§äº', '9958': 'âš¡ ä¸–ç´€é‹¼/é¢¨é›»',

    # === ğŸ”‹ BBU/é›»æ± /è¢«å‹•å…ƒä»¶ ===
    '3211': 'ğŸ”‹ é †é”/BBU', '6121': 'ğŸ”‹ æ–°æ™®/é›»æ± ', '6558': 'ğŸ”‹ èˆˆèƒ½é«˜',
    '2327': 'ğŸ§± åœ‹å·¨/è¢«å‹•å…ƒä»¶', '2492': 'ğŸ§± è¯æ–°ç§‘', 

    # === ğŸ”— é€£æ¥å™¨ ===
    '3533': 'ğŸ”— å˜‰æ¾¤/CPUæ’æ§½', '3217': 'ğŸ”— å„ªç¾¤', '3023': 'ğŸ”— ä¿¡é‚¦', '3605': 'ğŸ”— å®è‡´',

    # === ğŸ’° é‡‘èæµ·å˜¯ (é‡‘æ§/éŠ€è¡Œ) ===
    '2881': 'ğŸ’° å¯Œé‚¦é‡‘', '2882': 'ğŸ’° åœ‹æ³°é‡‘', '2891': 'ğŸ’° ä¸­ä¿¡é‡‘', '2886': 'ğŸ’° å…†è±é‡‘',
    '2884': 'ğŸ’° ç‰å±±é‡‘', '2885': 'ğŸ’° å…ƒå¤§é‡‘', '2883': 'ğŸ’° é–‹ç™¼é‡‘', '2892': 'ğŸ’° ç¬¬ä¸€é‡‘',
    '2880': 'ğŸ’° è¯å—é‡‘', '2890': 'ğŸ’° æ°¸è±é‡‘', '5880': 'ğŸ’° åˆåº«é‡‘', '2887': 'ğŸ’° å°æ–°é‡‘',

    # === ğŸš¢ èˆªé‹/å‚³ç”¢/é›†åœ˜ ===
    '2603': 'ğŸš¢ é•·æ¦®/è²¨æ«ƒ', '2609': 'ğŸš¢ é™½æ˜', '2615': 'ğŸš¢ è¬æµ·', 
    '2618': 'âœˆï¸ é•·æ¦®èˆª', '2610': 'âœˆï¸ è¯èˆª', '2637': 'ğŸš¢ æ…§æ´‹/æ•£è£',
    '1101': 'ğŸ—ï¸ å°æ³¥', '1102': 'ğŸ—ï¸ äºæ³¥', '2002': 'ğŸ—ï¸ ä¸­é‹¼', 
    '1301': 'ğŸ›¢ï¸ å°å¡‘', '1303': 'ğŸ›¢ï¸ å—äº', '1326': 'ğŸ›¢ï¸ å°åŒ–', '6505': 'ğŸ›¢ï¸ å°å¡‘åŒ–',
    '2207': 'ğŸš— å’Œæ³°è»Š', '2201': 'ğŸš— è£•éš†', '9904': 'ğŸ‘Ÿ å¯¶æˆ', '9910': 'ğŸ‘Ÿ è±æ³°',
    
    # === ğŸ å…‰å­¸/æ‰‹æ©Ÿ/æ¶ˆè²»é›» ===
    '3008': 'ğŸ å¤§ç«‹å…‰/é¡é ­', '3406': 'ğŸ ç‰æ™¶å…‰', '2474': 'ğŸ å¯æˆ',
    '2409': 'ğŸ“º å‹é”', '3481': 'ğŸ“º ç¾¤å‰µ', '4938': 'ğŸ’» å’Œç¢©'
}

# --- 4. å‚™ç”¨æ–¹æ¡ˆï¼šYahoo å¥‡æ‘©è‚¡å¸‚çˆ¬èŸ² ---
# ç•¶è‚¡ç¥¨ä¸åœ¨ä¸Šé¢çš„ Top 500 åå–®æ™‚ï¼Œç¨‹å¼æœƒè‡ªå‹•å»çˆ¬ Yahoo å¥‡æ‘©è‚¡å¸‚çš„åˆ†é¡
@st.cache_data(ttl=86400)
def fetch_tw_sector(stock_code):
    try:
        url = f"https://tw.stock.yahoo.com/quote/{stock_code}" 
        headers = {'User-Agent': 'Mozilla/5.0'}
        r = requests.get(url, headers=headers, timeout=3)
        if r.status_code == 200:
            soup = BeautifulSoup(r.text, 'html.parser')
            # æŠ“å– Yahoo ç”¢æ¥­é€£çµç‰¹å¾µ
            links = soup.find_all('a')
            for link in links:
                href = link.get('href', '')
                if '/h/category/' in href:
                    sector_name = link.text.strip()
                    return f"ğŸŒ {sector_name}" # åŠ å€‹åœ°çƒç¬¦è™Ÿä»£è¡¨æ˜¯ç¶²è·¯ä¸ŠæŠ“çš„
        return None
    except:
        return None

def get_detailed_industry(row):
    code = str(row['è‚¡ç¥¨ä»£è™Ÿ']).strip()
    name = str(row['è‚¡ç¥¨åç¨±']).strip()
    
    # 1. å„ªå…ˆæŸ¥ Top 500 å­—å…¸ (æœ€ç²¾æº–çš„æ–°èé¡Œæ)
    if code in STOCK_SECTOR_MAP:
        return STOCK_SECTOR_MAP[code]
    
    # 2. é—œéµå­—è£œæ¼ (è™•ç†æ˜é¡¯çš„é¡è‚¡)
    if 'é‡‘' in name and any(x in name for x in ['éŠ€', 'æ§', 'ä¿', 'å£½']): return 'ğŸ’° é‡‘èä¿éšª'
    if 'é›»' in name and 'å°' in name: return 'âš¡ å…¬ç”¨/é›»ä¿¡'
    if any(x in name for x in ['ETF', 'å‚µ', 'å¯Œé‚¦', 'å…ƒå¤§', 'åœ‹æ³°']): return 'ğŸ“Š ETF/åŸºé‡‘'

    # 3. æœ€å¾Œä¸€æ‹›ï¼šé€£ç¶²å»å• Yahoo
    online_sector = fetch_tw_sector(code)
    if online_sector:
        return online_sector
        
    return 'ğŸ“¦ å…¶ä»–'

# --- 5. ç‹€æ…‹åˆ¤æ–·èˆ‡æ¨£å¼ ---
def determine_status(row):
    if row['æŒæœ‰è‚¡æ•¸_old'] == 0 and row['æŒæœ‰è‚¡æ•¸'] > 0: return "âœ¨ æ–°é€²"
    elif row['æŒæœ‰è‚¡æ•¸_old'] > 0 and row['æŒæœ‰è‚¡æ•¸'] == 0: return "âŒ å‰”é™¤"
    elif row['è‚¡æ•¸è®ŠåŒ–_æ—¥'] > 0: return "ğŸ“ˆ åŠ ç¢¼"
    elif row['è‚¡æ•¸è®ŠåŒ–_æ—¥'] < 0: return "ğŸ“‰ æ¸›ç¢¼"
    else: return "æŒå¹³"

def highlight_status(val):
    if 'æ–°é€²' in val: return 'color: #d63384; font-weight: bold; background-color: #fce4ec;'
    if 'å‰”é™¤' in val: return 'color: #dc3545; font-weight: bold; background-color: #f8d7da;'
    if 'åŠ ç¢¼' in val: return 'color: #198754; font-weight: bold;'
    if 'æ¸›ç¢¼' in val: return 'color: #0d6efd;'
    return 'color: #6c757d;'

def color_change_text(val):
    if isinstance(val, (int, float)):
        return 'color: #198754' if val > 0 else 'color: #dc3545' if val < 0 else 'color: #adb5bd'
    return ''

# --- 6. ä¸»ç¨‹å¼ ---
def show_etf_dashboard(etf_code, etf_name):
    st.markdown("---")
    st.subheader(f"ğŸ“Š {etf_code} {etf_name}")
    
    csv_path = f'data/{etf_code}_history.csv'
    raw_df = load_data(csv_path)
    if raw_df is None or raw_df.empty:
        st.warning(f"âš ï¸ {etf_code} å°šç„¡è³‡æ–™")
        return

    df = clean_data(raw_df)
    all_dates = df['DateStr'].unique()
    if len(all_dates) == 0: return

    c1, c2, c3 = st.columns([1, 1, 2])
    with c1:
        date_now_str = st.selectbox(f"åŸºæº–æ—¥æœŸ", all_dates, index=0, key=f"d1_{etf_code}")
    
    idx_now = list(all_dates).index(date_now_str)
    idx_prev = idx_now + 1 if idx_now + 1 < len(all_dates) else idx_now
    idx_week = idx_now + 5 if idx_now + 5 < len(all_dates) else len(all_dates) - 1
    
    with c3:
        st.caption(f"ğŸ“… æ¯”è¼ƒå€é–“ï¼š vs å‰æ—¥ ({all_dates[idx_prev]}) | vs ä¸Šé€± ({all_dates[idx_week]})")
    
    try:
        df_now = df[df['DateStr'] == date_now_str].copy().set_index('è‚¡ç¥¨ä»£è™Ÿ')
        df_prev = df[df['DateStr'] == all_dates[idx_prev]].copy().set_index('è‚¡ç¥¨ä»£è™Ÿ')
        df_week = df[df['DateStr'] == all_dates[idx_week]].copy().set_index('è‚¡ç¥¨ä»£è™Ÿ')
        
        merged = df_now[['è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']].join(
            df_prev[['æŒæœ‰è‚¡æ•¸']], lsuffix='', rsuffix='_old', how='outer'
        ).fillna(0)
        
        merged = merged.join(df_week[['æŒæœ‰è‚¡æ•¸']], rsuffix='_week', how='outer').fillna(0)
        merged['è‚¡æ•¸è®ŠåŒ–_æ—¥'] = merged['æŒæœ‰è‚¡æ•¸'] - merged['æŒæœ‰è‚¡æ•¸_old']
        merged['è‚¡æ•¸è®ŠåŒ–_é€±'] = merged['æŒæœ‰è‚¡æ•¸'] - merged['æŒæœ‰è‚¡æ•¸_week']
        
        all_names = pd.concat([df_now['è‚¡ç¥¨åç¨±'], df_prev['è‚¡ç¥¨åç¨±']])
        name_map = all_names[~all_names.index.duplicated()].to_dict()
        merged['è‚¡ç¥¨åç¨±'] = merged.index.map(lambda x: name_map.get(x, x))
        
        merged = merged.reset_index()
        # åŸ·è¡Œç©¶æ¥µåˆ†é¡
        merged['ç”¢æ¥­'] = merged.apply(get_detailed_industry, axis=1)

    except Exception as e:
        st.error(f"è³‡æ–™è™•ç†éŒ¯èª¤: {e}")
        return

    # =========================================================================
    # KPI å„€è¡¨æ¿ (æ–°å¢æœ¬æ—¥åŠ ç¢¼ç‹)
    # =========================================================================
    
    top_buy_day = merged.sort_values('è‚¡æ•¸è®ŠåŒ–_æ—¥', ascending=False).iloc[0]
    buy_val_day = top_buy_day['è‚¡æ•¸è®ŠåŒ–_æ—¥']
    
    top_buy_week = merged.sort_values('è‚¡æ•¸è®ŠåŒ–_é€±', ascending=False).iloc[0]
    buy_val_week = top_buy_week['è‚¡æ•¸è®ŠåŒ–_é€±']

    day_act_count = len(merged[merged['è‚¡æ•¸è®ŠåŒ–_æ—¥'] != 0])
    
    k1, k2, k3, k4, k5 = st.columns(5)
    k1.metric("ğŸ“Š ç¸½æŒè‚¡æ•¸", f"{len(df_now)} æª”")
    
    if buy_val_day > 0:
        k2.metric("ğŸ‘‘ æœ¬æ—¥åŠ ç¢¼ç‹", f"{top_buy_day['è‚¡ç¥¨åç¨±']}", f"+{int(buy_val_day):,} è‚¡")
    else:
        k2.metric("ğŸ‘‘ æœ¬æ—¥åŠ ç¢¼ç‹", "ç„¡", "0")
        
    if buy_val_week > 0:
        k3.metric("ğŸ† æœ¬é€±åŠ ç¢¼ç‹", f"{top_buy_week['è‚¡ç¥¨åç¨±']}", f"+{int(buy_val_week):,} è‚¡")
    else:
        k3.metric("ğŸ† æœ¬é€±åŠ ç¢¼ç‹", "ç„¡", "0")

    k4.metric("âš¡ ä»Šæ—¥ç•°å‹•", f"{day_act_count} æª”")
    k5.metric("ğŸ’° æœ€å¤§æŒå€‰", f"{merged.sort_values('æ¬Šé‡', ascending=False).iloc[0]['è‚¡ç¥¨åç¨±']}")

    # =========================================================================
    # ğŸ”¥ 1. ä»Šæ—¥ç•°å‹•é€Ÿè¦½å€ (ç½®é ‚é¡¯ç¤ºï¼Œä¸€çœ¼çœ‹ç©¿)
    # =========================================================================
    st.markdown("### ğŸ”¥ ä»Šæ—¥ç„¦é»æ“ä½œ (Daily Highlights)")
    
    action_df = merged[merged['è‚¡æ•¸è®ŠåŒ–_æ—¥'] != 0].copy()
    
    if not action_df.empty:
        action_df['ç‹€æ…‹'] = action_df.apply(determine_status, axis=1)
        action_df['abs_change'] = action_df['è‚¡æ•¸è®ŠåŒ–_æ—¥'].abs()
        # æ’åºï¼šç‹€æ…‹å„ªå…ˆ (æ–°é€²/å‰”é™¤) -> è®Šå‹•é‡å¤§å°
        action_df = action_df.sort_values(['ç‹€æ…‹', 'abs_change'], ascending=[False, False])
        
        styled_action = action_df.style\
            .map(highlight_status, subset=['ç‹€æ…‹'])\
            .map(color_change_text, subset=['è‚¡æ•¸è®ŠåŒ–_æ—¥', 'è‚¡æ•¸è®ŠåŒ–_é€±'])
            
        st.dataframe(
            styled_action,
            column_order=['ç‹€æ…‹', 'è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'ç”¢æ¥­', 'è‚¡æ•¸è®ŠåŒ–_æ—¥', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡'],
            hide_index=True,
            use_container_width=True,
            column_config={
                "ç‹€æ…‹": st.column_config.TextColumn("å‹•æ…‹", width="small"),
                "è‚¡ç¥¨ä»£è™Ÿ": st.column_config.TextColumn("ä»£è™Ÿ", width="small"),
                "è‚¡ç¥¨åç¨±": st.column_config.TextColumn("åç¨±"),
                "ç”¢æ¥­": st.column_config.TextColumn("é¡Œæ (åœ°çƒ=è¯ç¶²æŸ¥è©¢)"),
                "è‚¡æ•¸è®ŠåŒ–_æ—¥": st.column_config.NumberColumn("ä»Šæ—¥å¢æ¸›", format="%+d"),
                "æŒæœ‰è‚¡æ•¸": st.column_config.NumberColumn("ç›®å‰åº«å­˜", format="%d"),
                "æ¬Šé‡": st.column_config.NumberColumn("æ¬Šé‡", format="%.2f%%")
            }
        )
    else:
        st.info("ğŸ˜´ ä»Šæ—¥ç¶“ç†äººèººå¹³ï¼Œç„¡ä»»ä½•è²·è³£æ“ä½œ")

    # =========================================================================
    # ğŸ“Š 2. åœ–è¡¨åˆ†æå€
    # =========================================================================
    col_chart1, col_chart2 = st.columns(2)
    with col_chart1:
        st.caption("ğŸ­ æŒè‚¡é¡Œæåˆ†ä½ˆ (Top 500 åˆ†é¡)")
        industry_counts = merged[merged['æŒæœ‰è‚¡æ•¸']>0]['ç”¢æ¥­'].value_counts()
        if not industry_counts.empty:
            fig1 = px.pie(
                values=industry_counts.values, names=industry_counts.index, hole=0.5,
                color_discrete_sequence=px.colors.qualitative.Prism # ä½¿ç”¨é®®æ˜é…è‰²
            )
            fig1.update_traces(textinfo='percent+label', textposition='inside')
            fig1.update_layout(showlegend=False, margin=dict(l=10, r=10, t=10, b=10), height=300)
            st.plotly_chart(fig1, use_container_width=True)

    with col_chart2:
        st.caption("ğŸ“… è¿‘ä¸€é€±å‹•ä½œ (Top 10)")
        week_movers = merged[merged['è‚¡æ•¸è®ŠåŒ–_é€±'].abs() > 0].sort_values('è‚¡æ•¸è®ŠåŒ–_é€±', ascending=False).head(10)
        if not week_movers.empty:
            fig2 = go.Figure()
            fig2.add_trace(go.Bar(
                y=week_movers['è‚¡ç¥¨åç¨±'], x=week_movers['è‚¡æ•¸è®ŠåŒ–_é€±'], orientation='h',
                marker=dict(color=week_movers['è‚¡æ•¸è®ŠåŒ–_é€±'], colorscale='Tealrose', cmid=0)
            ))
            fig2.update_layout(height=300, margin=dict(l=0, r=0, t=10, b=10), xaxis_title=None)
            st.plotly_chart(fig2, use_container_width=True)

    # =========================================================================
    # ğŸ“‹ 3. å®Œæ•´æŒè‚¡æ¸…å–® (æŠ˜ç–Šéš±è—ï¼ŒæŒ‰æ–°èé¡Œæåˆ†é¡)
    # =========================================================================
    with st.expander("ğŸ“‚ æŸ¥çœ‹å®Œæ•´æŒè‚¡æ¸…å–® (æŒ‰æ–°èé¡Œæåˆ†é¡)", expanded=False):
        
        table_df = merged[(merged['æŒæœ‰è‚¡æ•¸'] > 0) | (merged['æŒæœ‰è‚¡æ•¸_old'] > 0)].copy()
        table_df['ç‹€æ…‹'] = table_df.apply(determine_status, axis=1)

        trend_col = []
        for code in table_df['è‚¡ç¥¨ä»£è™Ÿ']:
            trend_col.append(get_trend_data(df, code))
        table_df['æ­·å²èµ°å‹¢'] = trend_col

        # è¨ˆç®—æ¬Šé‡æ’åº
        industry_stats = table_df.groupby('ç”¢æ¥­')['æ¬Šé‡'].sum().sort_values(ascending=False)
        
        for industry_name, total_weight in industry_stats.items():
            sub_df = table_df[table_df['ç”¢æ¥­'] == industry_name].copy()
            sub_df = sub_df.sort_values('æ¬Šé‡', ascending=False)
            
            # ä½¿ç”¨ Markdown è£½ä½œæ¼‚äº®çš„åˆ†é¡æ¨™é¡Œ
            st.markdown(f"""
            <div class='industry-header'>
                {industry_name} <span style='font-size:0.9rem; color:#666; font-weight:normal;'>(ä½”æ¯”: {total_weight:.2f}%)</span>
            </div>
            """, unsafe_allow_html=True)
            
            styled_sub_df = sub_df.style\
                .map(highlight_status, subset=['ç‹€æ…‹'])\
                .map(color_change_text, subset=['è‚¡æ•¸è®ŠåŒ–_æ—¥', 'è‚¡æ•¸è®ŠåŒ–_é€±'])
            
            st.dataframe(
                styled_sub_df,
                column_order=['ç‹€æ…‹', 'è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æ¬Šé‡', 'è‚¡æ•¸è®ŠåŒ–_æ—¥', 'è‚¡æ•¸è®ŠåŒ–_é€±', 'æŒæœ‰è‚¡æ•¸', 'æ­·å²èµ°å‹¢'],
                hide_index=True,
                use_container_width=True,
                column_config={
                    "ç‹€æ…‹": st.column_config.TextColumn("å‹•æ…‹", width="small"),
                    "è‚¡ç¥¨ä»£è™Ÿ": st.column_config.TextColumn("ä»£è™Ÿ", width="small"),
                    "è‚¡ç¥¨åç¨±": st.column_config.TextColumn("åç¨±"),
                    "æ¬Šé‡": st.column_config.ProgressColumn("æ¬Šé‡", format="%.2f%%", min_value=0, max_value=10),
                    "è‚¡æ•¸è®ŠåŒ–_æ—¥": st.column_config.NumberColumn("æ—¥å¢æ¸›", format="%+d"),
                    "è‚¡æ•¸è®ŠåŒ–_é€±": st.column_config.NumberColumn("é€±å¢æ¸›", format="%+d"),
                    "æŒæœ‰è‚¡æ•¸": st.column_config.NumberColumn("åº«å­˜", format="%d"),
                    "æ­·å²èµ°å‹¢": st.column_config.LineChartColumn("30æ—¥è¶¨å‹¢", width="medium")
                }
            )

# åŸ·è¡Œ
show_etf_dashboard("00981A", "ä¸»å‹•çµ±ä¸€å°è‚¡å¢é•·")
show_etf_dashboard("00991A", "ä¸»å‹•å¾©è¯æœªä¾†50")
