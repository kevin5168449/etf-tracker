import streamlit as st
import pandas as pd
import os
import plotly.express as px
import plotly.graph_objects as go
import requests
from bs4 import BeautifulSoup

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="ETF æˆ°æƒ…å®¤ Pro (å®Œæ•´ç‰ˆ)", page_icon="ğŸ¦", layout="wide")

# --- CSS å„ªåŒ– ---
st.markdown("""
<style>
    .stDataFrame { font-size: 1.05rem; }
    div[data-testid="stMetricValue"] {
        font-size: 1.5rem !important;
        font-weight: 700;
        color: #2c3e50;
    }
    div[data-testid="stSelectbox"] {
        font-size: 1.1rem;
    }
    /* è®“ç¾é‡‘æ°´ä½çš„å¡ç‰‡ç‰¹åˆ¥ä¸€é» */
    .cash-card {
        background-color: #e3f2fd;
        padding: 10px;
        border-radius: 8px;
        border: 1px solid #90caf9;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ¦ 2026 ä¸»å‹•å¼ ETF æˆ°æƒ…å®¤ (ç¾é‡‘æ°´ä½ + ç”¢æ¥­æµå‘ç‰ˆ)")

# --- 1. è³‡æ–™è™•ç†æ ¸å¿ƒ ---
@st.cache_data(ttl=60)
def load_data(file_path):
    if not os.path.exists(file_path): return None
    try:
        return pd.read_csv(file_path, dtype=str, on_bad_lines='skip', engine='python', encoding='utf-8-sig')
    except: return None

def clean_data(df):
    if df is None or df.empty: return pd.DataFrame()
    for col in ['æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']:
        if col not in df.columns: df[col] = '0'
    for col in ['æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']:
        df[col] = df[col].astype(str).str.replace(',', '').str.replace('%', '')
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    if 'Date' in df.columns:
        df['Date'] = pd.to_datetime(df['Date'])
        df['DateStr'] = df['Date'].dt.strftime('%Y-%m-%d')
    else: return pd.DataFrame()
    df = df.drop_duplicates(subset=['DateStr', 'è‚¡ç¥¨ä»£è™Ÿ'], keep='first')
    df = df.sort_values('Date', ascending=False)
    return df

def get_trend_data(full_df, stock_code):
    try:
        history = full_df[full_df['è‚¡ç¥¨ä»£è™Ÿ'] == stock_code].sort_values('Date', ascending=True)
        data = history['æ¬Šé‡'].tail(30).tolist()
        if not data or all(x == 0 for x in data): return [0.0, 0.0]
        return data
    except: return [0.0, 0.0]

# --- 2. ç°¡ç´„åˆ†é¡ç³»çµ± ---
CORE_SECTOR_MAP = {
    '2330': 'åŠå°é«”æ¥­', '2303': 'åŠå°é«”æ¥­', '2454': 'åŠå°é«”æ¥­', '3711': 'åŠå°é«”æ¥­',
    '3443': 'åŠå°é«”æ¥­', '3661': 'åŠå°é«”æ¥­', '3034': 'åŠå°é«”æ¥­', '2379': 'åŠå°é«”æ¥­',
    '2317': 'é›»è…¦é€±é‚Š', '2382': 'é›»è…¦é€±é‚Š', '3231': 'é›»è…¦é€±é‚Š', '2356': 'é›»è…¦é€±é‚Š',
    '3017': 'é›»è…¦é€±é‚Š', '3324': 'é›»è…¦é€±é‚Š', '2376': 'é›»è…¦é€±é‚Š', '6669': 'é›»è…¦é€±é‚Š',
    '2301': 'é›»è…¦é€±é‚Š', '3217': 'é›»è…¦é€±é‚Š', '3533': 'é›»å­é›¶çµ„ä»¶', '2308': 'é›»å­é›¶çµ„ä»¶',
    '2345': 'é€šä¿¡ç¶²è·¯', '3045': 'é€šä¿¡ç¶²è·¯', '2412': 'é€šä¿¡ç¶²è·¯', '4904': 'é€šä¿¡ç¶²è·¯',
    '2881': 'é‡‘èä¿éšª', '2882': 'é‡‘èä¿éšª', '2891': 'é‡‘èä¿éšª', '2886': 'é‡‘èä¿éšª',
    '2884': 'é‡‘èä¿éšª', '2892': 'é‡‘èä¿éšª', '5880': 'é‡‘èä¿éšª',
    '2603': 'èˆªé‹æ¥­', '2609': 'èˆªé‹æ¥­', '2615': 'èˆªé‹æ¥­', '2618': 'èˆªé‹æ¥­',
    '1513': 'é›»æ©Ÿæ©Ÿæ¢°', '1519': 'é›»æ©Ÿæ©Ÿæ¢°', '1605': 'é›»å™¨é›»çºœ', '2002': 'é‹¼éµå·¥æ¥­'
}

@st.cache_data(ttl=86400)
def fetch_yahoo_sector(stock_code):
    try:
        url = f"https://tw.stock.yahoo.com/quote/{stock_code}" 
        headers = {'User-Agent': 'Mozilla/5.0'}
        r = requests.get(url, headers=headers, timeout=2)
        if r.status_code == 200:
            soup = BeautifulSoup(r.text, 'html.parser')
            links = soup.find_all('a')
            for link in links:
                href = link.get('href', '')
                if '/h/category/' in href:
                    return link.text.strip()
        return None
    except: return None

def get_industry(row):
    code = str(row['è‚¡ç¥¨ä»£è™Ÿ']).strip()
    if code in CORE_SECTOR_MAP: return CORE_SECTOR_MAP[code]
    online_sector = fetch_yahoo_sector(code)
    if online_sector: return f"{online_sector}"
    return 'å…¶ä»–'

# --- 3. ç‹€æ…‹åˆ¤æ–·èˆ‡é¡è‰²é‚è¼¯ (å°è‚¡é…è‰²) ---
def determine_status(row):
    if row['æŒæœ‰è‚¡æ•¸_old'] == 0 and row['æŒæœ‰è‚¡æ•¸'] > 0: return "âœ¨ æ–°é€²"
    elif row['æŒæœ‰è‚¡æ•¸_old'] > 0 and row['æŒæœ‰è‚¡æ•¸'] == 0: return "âŒ å‰”é™¤"
    elif row['è‚¡æ•¸è®ŠåŒ–_æ—¥'] > 0: return "ğŸ“ˆ åŠ ç¢¼"
    elif row['è‚¡æ•¸è®ŠåŒ–_æ—¥'] < 0: return "ğŸ“‰ æ¸›ç¢¼"
    else: return "æŒå¹³"

def highlight_status(val):
    if 'æ–°é€²' in val: return 'color: #d32f2f; font-weight: bold;'
    if 'å‰”é™¤' in val: return 'color: #2e7d32; font-weight: bold;'
    if 'åŠ ç¢¼' in val: return 'color: #d32f2f; font-weight: bold;'
    if 'æ¸›ç¢¼' in val: return 'color: #2e7d32; font-weight: bold;'
    return 'color: #999;'

def color_change_text(val):
    if isinstance(val, (int, float)):
        return 'color: #d32f2f' if val > 0 else 'color: #2e7d32' if val < 0 else 'color: #ccc'
    return ''

# --- 4. ä¸»ç¨‹å¼ ---
def show_etf_dashboard(etf_code, etf_name):
    st.markdown("---")
    st.subheader(f"ğŸ“Š {etf_code} {etf_name}")
    
    csv_path = f'data/{etf_code}_history.csv'
    raw_df = load_data(csv_path)
    if raw_df is None or raw_df.empty:
        st.warning(f"âš ï¸ {etf_code} ç„¡è³‡æ–™")
        return

    df = clean_data(raw_df)
    all_dates = df['DateStr'].unique()
    if len(all_dates) == 0: return

    # --- æ—¥æœŸé¸å–® ---
    date_options = {}
    for i, date_str in enumerate(all_dates):
        idx_prev = i + 1 if i + 1 < len(all_dates) else i
        idx_week = i + 5 if i + 5 < len(all_dates) else len(all_dates) - 1
        prev_date = all_dates[idx_prev]
        week_date = all_dates[idx_week]
        
        if i == len(all_dates) - 1:
             label = f"{date_str} (åˆå§‹è³‡æ–™)"
        else:
             label = f"{date_str} (vs å‰æ—¥ {prev_date[5:]} | vs ä¸Šé€± {week_date[5:]})"
        date_options[date_str] = label

    date_now_str = st.selectbox(
        "ğŸ“… é¸æ“‡åŸºæº–æ—¥æœŸ", 
        options=all_dates, 
        index=0, 
        format_func=lambda x: date_options[x],
        key=f"d1_{etf_code}"
    )
    
    idx_now = list(all_dates).index(date_now_str)
    idx_prev = idx_now + 1 if idx_now + 1 < len(all_dates) else idx_now
    idx_week = idx_now + 5 if idx_now + 5 < len(all_dates) else len(all_dates) - 1
    
    try:
        df_now = df[df['DateStr'] == date_now_str].copy().set_index('è‚¡ç¥¨ä»£è™Ÿ')
        df_prev = df[df['DateStr'] == all_dates[idx_prev]].copy().set_index('è‚¡ç¥¨ä»£è™Ÿ')
        df_week = df[df['DateStr'] == all_dates[idx_week]].copy().set_index('è‚¡ç¥¨ä»£è™Ÿ')
        
        merged = df_now[['è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']].join(
            df_prev[['æŒæœ‰è‚¡æ•¸']], lsuffix='', rsuffix='_old', how='outer'
        ).fillna(0)
        
        merged = merged.join(df_week[['æŒæœ‰è‚¡æ•¸']], rsuffix='_week', how='outer').fillna(0)
        merged['è‚¡æ•¸è®ŠåŒ–_æ—¥'] = merged['æŒæœ‰è‚¡æ•¸'] - merged['æŒæœ‰è‚¡æ•¸_old']
        merged['è‚¡æ•¸è®ŠåŒ–_é€±'] = merged['æŒæœ‰è‚¡æ•¸'] - merged['æŒæœ‰è‚¡æ•¸_week']
        
        all_names = pd.concat([df_now['è‚¡ç¥¨åç¨±'], df_prev['è‚¡ç¥¨åç¨±']])
        name_map = all_names[~all_names.index.duplicated()].to_dict()
        merged['è‚¡ç¥¨åç¨±'] = merged.index.map(lambda x: name_map.get(x, x))
        
        merged = merged.reset_index()
        merged['ç”¢æ¥­'] = merged.apply(get_industry, axis=1)

    except Exception as e:
        st.error(f"Error: {e}")
        return

    # --- KPI è¨ˆç®— (å«ç¾é‡‘æ°´ä½) ---
    top_buy_day = merged.sort_values('è‚¡æ•¸è®ŠåŒ–_æ—¥', ascending=False).iloc[0]
    buy_val_day = top_buy_day['è‚¡æ•¸è®ŠåŒ–_æ—¥']
    
    top_buy_week = merged.sort_values('è‚¡æ•¸è®ŠåŒ–_é€±', ascending=False).iloc[0]
    buy_val_week = top_buy_week['è‚¡æ•¸è®ŠåŒ–_é€±']
    
    day_act_count = len(merged[merged['è‚¡æ•¸è®ŠåŒ–_æ—¥'] != 0])
    
    # è¨ˆç®—æŒè‚¡ç¸½æ¬Šé‡ (å‰©é¤˜çš„å‡è¨­ç‚ºç¾é‡‘/æœŸè²¨)
    total_stock_weight = merged['æ¬Šé‡'].sum()
    cash_position = 100.0 - total_stock_weight
    
    # é¡¯ç¤º KPI (5 æ¬„)
    k1, k2, k3, k4, k5 = st.columns(5)
    
    # 1. ç¾é‡‘æ°´ä½ (å¦‚æœ <0 ä»£è¡¨è³‡æ–™æœ‰èª¤æˆ–æ§“æ¡¿ï¼Œé€™è£¡è¨­åº•é™ç‚º0)
    cash_display = max(0.0, cash_position)
    k1.metric("ğŸ’° ç¾é‡‘/é¿éšªæ°´ä½", f"{cash_display:.2f}%", delta=None) # ä¸é¡¯ç¤ºæ¼²è·Œï¼Œåªé¡¯ç¤ºæ°´ä½
    
    # 2. æœ¬æ—¥åŠ ç¢¼
    if buy_val_day > 0:
        k2.metric("ğŸ‘‘ æœ¬æ—¥åŠ ç¢¼", f"{top_buy_day['è‚¡ç¥¨åç¨±']}", f"+{int(buy_val_day):,}")
    else:
        k2.metric("ğŸ‘‘ æœ¬æ—¥åŠ ç¢¼", "ç„¡", "0")
    
    # 3. æœ¬é€±åŠ ç¢¼
    if buy_val_week > 0:
        k3.metric("ğŸ† æœ¬é€±åŠ ç¢¼", f"{top_buy_week['è‚¡ç¥¨åç¨±']}", f"+{int(buy_val_week):,}")
    else:
        k3.metric("ğŸ† æœ¬é€±åŠ ç¢¼", "ç„¡", "0")

    # 4. ç•°å‹•æ•¸
    k4.metric("âš¡ ä»Šæ—¥ç•°å‹•", f"{day_act_count}")
    
    # 5. æŒè‚¡æ•¸
    k5.metric("ğŸ“Š æŒè‚¡æª”æ•¸", f"{len(df_now)}")

    # --- Section 1: ä»Šæ—¥ç•°å‹• (ç½®é ‚) ---
    st.markdown("### ğŸ”¥ ä»Šæ—¥ç„¦é»ç•°å‹•")
    action_df = merged[merged['è‚¡æ•¸è®ŠåŒ–_æ—¥'] != 0].copy()
    
    if not action_df.empty:
        action_df['ç‹€æ…‹'] = action_df.apply(determine_status, axis=1)
        action_df['abs_change'] = action_df['è‚¡æ•¸è®ŠåŒ–_æ—¥'].abs()
        action_df = action_df.sort_values(['ç‹€æ…‹', 'abs_change'], ascending=[False, False])
        
        styled_action = action_df.style\
            .map(highlight_status, subset=['ç‹€æ…‹'])\
            .map(color_change_text, subset=['è‚¡æ•¸è®ŠåŒ–_æ—¥', 'è‚¡æ•¸è®ŠåŒ–_é€±'])
            
        st.dataframe(
            styled_action,
            column_order=['ç‹€æ…‹', 'è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'ç”¢æ¥­', 'è‚¡æ•¸è®ŠåŒ–_æ—¥', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡'],
            hide_index=True,
            use_container_width=True,
            column_config={
                "ç‹€æ…‹": st.column_config.TextColumn("å‹•æ…‹", width="small"),
                "è‚¡æ•¸è®ŠåŒ–_æ—¥": st.column_config.NumberColumn("ä»Šæ—¥å¢æ¸›", format="%+d"),
                "æ¬Šé‡": st.column_config.NumberColumn("æ¬Šé‡", format="%.2f%%")
            }
        )
    else:
        st.info("ğŸ˜´ ä»Šæ—¥ç¶“ç†äººæŒ‰å…µä¸å‹• (ç„¡è²·è³£ç´€éŒ„)")

    # --- Section 2: æˆ°æƒ…åœ–è¡¨å€ (ç†±åŠ›åœ– + ç”¢æ¥­æµå‘) ---
    col1, col2 = st.columns([2, 1]) # å·¦é‚Šå¯¬ä¸€é»çµ¦ç†±åŠ›åœ–
    
    with col1:
        st.markdown("### ğŸ—ºï¸ è³‡é‡‘ç†±åŠ›åœ– (é¢ç©=æ¬Šé‡)")
        treemap_df = merged[merged['æ¬Šé‡'] > 0.1].copy() 
        if not treemap_df.empty:
            custom_colors = [[0.0, '#2e7d32'], [0.5, '#ffffff'], [1.0, '#d32f2f']]
            fig_map = px.treemap(
                treemap_df,
                path=['ç”¢æ¥­', 'è‚¡ç¥¨åç¨±'],
                values='æ¬Šé‡',
                color='è‚¡æ•¸è®ŠåŒ–_é€±',
                color_continuous_scale=custom_colors,
                color_continuous_midpoint=0,
                custom_data=['æŒæœ‰è‚¡æ•¸', 'è‚¡æ•¸è®ŠåŒ–_é€±']
            )
            fig_map.update_traces(hovertemplate='<b>%{label}</b><br>æ¬Šé‡: %{value:.2f}%<br>é€±å¢æ¸›: %{customdata[1]:+d}')
            fig_map.update_layout(margin=dict(t=0, l=0, r=0, b=0), height=400)
            st.plotly_chart(fig_map, use_container_width=True)

    with col2:
        st.markdown("### ğŸŒŠ æœ¬é€±ç”¢æ¥­æµå‘")
        # è¨ˆç®—å„ç”¢æ¥­çš„æœ¬é€±è‚¡æ•¸è®ŠåŒ–ç¸½å’Œ (ç°¡å–®ä¼°ç®—)
        # æ³¨æ„ï¼šåš´æ ¼ä¾†èªªæ‡‰è©²ç®—é‡‘é¡ï¼Œä½†é€™è£¡ç”¨è‚¡æ•¸è®ŠåŒ–åšè¿‘ä¼¼è¶¨å‹¢
        sector_flow = merged.groupby('ç”¢æ¥­')['è‚¡æ•¸è®ŠåŒ–_é€±'].sum().sort_values(ascending=False)
        # åªå–è®Šå‹•æœ€å¤§çš„å‰ 5 åå’Œå¾Œ 5 å
        top_sectors = pd.concat([sector_flow.head(3), sector_flow.tail(3)])
        
        if not top_sectors.empty:
            # é¡è‰²ï¼šå¤§æ–¼0ç´…ï¼Œå°æ–¼0ç¶ 
            colors = ['#d32f2f' if v > 0 else '#2e7d32' for v in top_sectors.values]
            
            fig_bar = go.Figure(go.Bar(
                x=top_sectors.values,
                y=top_sectors.index,
                orientation='h',
                marker_color=colors
            ))
            fig_bar.update_layout(
                margin=dict(t=0, l=0, r=0, b=0), 
                height=400,
                xaxis_title="è‚¡æ•¸å¢æ¸› (ç´„ç•¥)",
                yaxis=dict(autorange="reversed") # è®“æ¼²çš„æ’ä¸Šé¢
            )
            st.plotly_chart(fig_bar, use_container_width=True)

    # --- Section 3: å®Œæ•´æŒè‚¡åˆ—è¡¨ (å–®ä¸€å¤§è¡¨æ ¼) ---
    with st.expander("ğŸ“‚ å®Œæ•´æŒè‚¡æ¸…å–® (é»æ“Šè¡¨é ­å¯æ’åº)", expanded=False):
        table_df = merged[(merged['æŒæœ‰è‚¡æ•¸'] > 0) | (merged['æŒæœ‰è‚¡æ•¸_old'] > 0)].copy()
        table_df['ç‹€æ…‹'] = table_df.apply(determine_status, axis=1)
        
        trend_col = []
        for code in table_df['è‚¡ç¥¨ä»£è™Ÿ']:
            trend_col.append(get_trend_data(df, code))
        table_df['æ­·å²èµ°å‹¢'] = trend_col

        table_df = table_df.sort_values(['ç”¢æ¥­', 'æ¬Šé‡'], ascending=[True, False])

        styled_df = table_df.style\
            .map(highlight_status, subset=['ç‹€æ…‹'])\
            .map(color_change_text, subset=['è‚¡æ•¸è®ŠåŒ–_æ—¥', 'è‚¡æ•¸è®ŠåŒ–_é€±'])
        
        st.dataframe(
            styled_df,
            column_order=['ç‹€æ…‹', 'è‚¡ç¥¨ä»£è™Ÿ', 'ç”¢æ¥­', 'è‚¡ç¥¨åç¨±', 'æ¬Šé‡', 'è‚¡æ•¸è®ŠåŒ–_æ—¥', 'è‚¡æ•¸è®ŠåŒ–_é€±', 'æŒæœ‰è‚¡æ•¸', 'æ­·å²èµ°å‹¢'],
            hide_index=True,
            use_container_width=True,
            column_config={
                "ç‹€æ…‹": st.column_config.TextColumn("å‹•æ…‹", width="small"),
                "è‚¡ç¥¨ä»£è™Ÿ": st.column_config.TextColumn("ä»£è™Ÿ", width="small"),
                "ç”¢æ¥­": st.column_config.TextColumn("é¡åˆ¥", width="medium"),
                "è‚¡ç¥¨åç¨±": st.column_config.TextColumn("åç¨±"),
                "æ¬Šé‡": st.column_config.ProgressColumn("æ¬Šé‡", format="%.2f%%", min_value=0, max_value=10),
                "è‚¡æ•¸è®ŠåŒ–_æ—¥": st.column_config.NumberColumn("æ—¥å¢æ¸›", format="%+d"),
                "è‚¡æ•¸è®ŠåŒ–_é€±": st.column_config.NumberColumn("é€±å¢æ¸›", format="%+d"),
                "æŒæœ‰è‚¡æ•¸": st.column_config.NumberColumn("åº«å­˜", format="%d"),
                "æ­·å²èµ°å‹¢": st.column_config.LineChartColumn("30æ—¥è¶¨å‹¢", width="small")
            }
        )

# åŸ·è¡Œ
show_etf_dashboard("00981A", "ä¸»å‹•çµ±ä¸€å°è‚¡å¢é•·")
show_etf_dashboard("00991A", "ä¸»å‹•å¾©è¯æœªä¾†50")
