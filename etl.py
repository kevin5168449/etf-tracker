import pandas as pd
import requests
import os
from datetime import datetime, timedelta
import io
import time
import shutil

# --- Selenium è¨­å®š ---
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By

# --- è¨­å®š Discord Webhook ---
DISCORD_WEBHOOK = os.environ.get("DISCORD_WEBHOOK")

def send_discord_notify(msg):
    if not DISCORD_WEBHOOK: 
        print("âš ï¸ æœªè¨­å®š Discord Webhookï¼Œè·³éé€šçŸ¥")
        return
    data = {"content": msg, "username": "ETF ç›£æ§å°å¹«æ‰‹"}
    try: 
        requests.post(DISCORD_WEBHOOK, json=data)
        print("âœ… Discord é€šçŸ¥å·²ç™¼é€")
    except Exception as e: 
        print(f"âŒ Discord é€šçŸ¥ç™¼é€å¤±æ•—: {e}")

def get_roc_date_string(delta_days=0):
    target_date = datetime.now() + timedelta(days=delta_days)
    roc_year = target_date.year - 1911
    return f"{roc_year}/{target_date.month:02d}/{target_date.day:02d}"

# â˜…â˜…â˜… æ–°å¢ï¼šç”Ÿæˆæ¯æ—¥ç°¡æ˜“æˆ°å ± (è®“ Discord è¬›äººè©±) â˜…â˜…â˜…
def generate_daily_report(df):
    try:
        # ç¢ºä¿æ—¥æœŸæ˜¯æ’åºçš„ (æœ€æ–°çš„åœ¨ä¸Šé¢)
        df['DateObj'] = pd.to_datetime(df['Date'])
        dates = df['DateObj'].sort_values(ascending=False).unique()
        
        if len(dates) < 2:
            return "\n(âš ï¸ è³‡æ–™ç´¯ç©å¤©æ•¸ä¸è¶³ï¼Œæš«ç„¡æ³•åˆ†æè®Šå‹•)"
            
        # å–å¾—ä»Šå¤©å’Œæ˜¨å¤©çš„è³‡æ–™
        d_now = dates[0]
        d_prev = dates[1]
        
        df_now = df[df['DateObj'] == d_now].set_index('è‚¡ç¥¨ä»£è™Ÿ')
        df_prev = df[df['DateObj'] == d_prev].set_index('è‚¡ç¥¨ä»£è™Ÿ')
        
        # åˆä½µæ¯”å°
        merged = df_now[['è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸']].join(
            df_prev[['æŒæœ‰è‚¡æ•¸']], lsuffix='', rsuffix='_old', how='outer'
        ).fillna(0)
        
        merged['è‚¡æ•¸è®ŠåŒ–'] = merged['æŒæœ‰è‚¡æ•¸'] - merged['æŒæœ‰è‚¡æ•¸_old']
        
        # è£œåç¨± (è‹¥å‰”é™¤ï¼Œåç¨±å¯èƒ½åœ¨ old è£¡)
        name_map = pd.concat([df_now['è‚¡ç¥¨åç¨±'], df_prev['è‚¡ç¥¨åç¨±']]).to_dict()
        merged['è‚¡ç¥¨åç¨±'] = merged.index.map(name_map).fillna(merged.index)
        
        # 1. æ‰¾å‡ºæ–°é€²æ¦œ
        new_entries = merged[(merged['æŒæœ‰è‚¡æ•¸_old'] == 0) & (merged['æŒæœ‰è‚¡æ•¸'] > 0)]
        # 2. æ‰¾å‡ºå‰”é™¤æ¦œ
        exited = merged[(merged['æŒæœ‰è‚¡æ•¸_old'] > 0) & (merged['æŒæœ‰è‚¡æ•¸'] == 0)]
        # 3. æ‰¾å‡ºåŠ ç¢¼ç‹ (è‚¡æ•¸å¢åŠ æœ€å¤š)
        top_buy = merged.sort_values('è‚¡æ•¸è®ŠåŒ–', ascending=False).head(1)
        # 4. æ‰¾å‡ºæ¸›ç¢¼ç‹ (è‚¡æ•¸æ¸›å°‘æœ€å¤š)
        top_sell = merged.sort_values('è‚¡æ•¸è®ŠåŒ–', ascending=True).head(1)
        
        report = ""
        
        # æ’°å¯«å ±å‘Šå…§å®¹
        if not new_entries.empty:
            names = ", ".join(new_entries['è‚¡ç¥¨åç¨±'].tolist())
            report += f"\nğŸ”¥ **æ–°é€²æ¦œ**: {names}"
            
        if not exited.empty:
            names = ", ".join(exited['è‚¡ç¥¨åç¨±'].tolist())
            report += f"\nğŸ‘‹ **å‰”é™¤æ¦œ**: {names}"
            
        if not top_buy.empty and top_buy['è‚¡æ•¸è®ŠåŒ–'].values[0] > 0:
            name = top_buy['è‚¡ç¥¨åç¨±'].values[0]
            change = int(top_buy['è‚¡æ•¸è®ŠåŒ–'].values[0])
            report += f"\nğŸ“ˆ **åŠ ç¢¼ç‹**: {name} (+{change:,} è‚¡)"
            
        if not top_sell.empty and top_sell['è‚¡æ•¸è®ŠåŒ–'].values[0] < 0:
            name = top_sell['è‚¡ç¥¨åç¨±'].values[0]
            change = int(top_sell['è‚¡æ•¸è®ŠåŒ–'].values[0])
            report += f"\nğŸ“‰ **æ¸›ç¢¼ç‹**: {name} ({change:,} è‚¡)"
            
        if report == "":
            report = "\n(ğŸ’¤ ä»Šæ—¥æŒè‚¡ç„¡é¡¯è‘—è®ŠåŒ–)"
            
        return report

    except Exception as e:
        return f"\n(âš ï¸ æˆ°å ±ç”Ÿæˆå¤±æ•—: {e})"

# â˜…â˜…â˜… æ ¸å¿ƒå¤§è…¦ï¼šæ¨™æº–åŒ–æ¸…æ´—å‡½å¼ â˜…â˜…â˜…
def standardize_df(df, source_name=""):
    if df.empty: return df
    
    # å¼·åˆ¶ä½ç½®å°æ‡‰
    if source_name == "00981A" and len(df.columns) >= 4:
        df = df.iloc[:, :4] 
        df.columns = ['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']
    elif source_name == "00991A" and len(df.columns) >= 5:
        df = df.iloc[:, [0, 1, 2, 4]]
        df.columns = ['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']
    else:
        col_map = {
            'è‚¡ç¥¨ä»£è™Ÿ': ['è‚¡ç¥¨ä»£è™Ÿ', 'ä»£è™Ÿ', 'è­‰åˆ¸ä»£è™Ÿ', 'Code'],
            'è‚¡ç¥¨åç¨±': ['è‚¡ç¥¨åç¨±', 'åç¨±', 'è­‰åˆ¸åç¨±', 'Name'],
            'æŒæœ‰è‚¡æ•¸': ['æŒæœ‰è‚¡æ•¸', 'è‚¡æ•¸', 'åº«å­˜è‚¡æ•¸', 'Shares'],
            'æ¬Šé‡': ['æ¬Šé‡', 'æ¬Šé‡(%)', 'æ¯”ä¾‹', 'æŒè‚¡(%)', 'æŒè‚¡æ¯”ç‡', 'Weight']
        }
        for target, cands in col_map.items():
            for cand in cands:
                matches = [c for c in df.columns if str(c).strip() in cands]
                if matches:
                    df.rename(columns={matches[0]: target}, inplace=True)
                    break

    for col in ['æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']:
        if col in df.columns:
            df[col] = df[col].astype(str).str.replace('%', '').str.replace(',', '').str.replace('-', '0')
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    required = ['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']
    for req in required:
        if req not in df.columns:
            if req == 'æ¬Šé‡': df[req] = 0 
            elif req == 'è‚¡ç¥¨ä»£è™Ÿ': df[req] = 'N/A'
    
    df = df[df['è‚¡ç¥¨ä»£è™Ÿ'] != 'è‚¡ç¥¨ä»£è™Ÿ']
    df = df[df['è‚¡ç¥¨ä»£è™Ÿ'] != 'è­‰åˆ¸ä»£è™Ÿ']

    return df[['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'æŒæœ‰è‚¡æ•¸', 'æ¬Šé‡']]

def smart_read_excel(content):
    try:
        temp_df = pd.read_excel(io.BytesIO(content), header=None, nrows=20)
        header_row = -1
        for i, row in temp_df.iterrows():
            row_str = row.astype(str).str.cat()
            if "è‚¡ç¥¨ä»£è™Ÿ" in row_str or "Code" in row_str:
                header_row = i
                break
        return pd.read_excel(io.BytesIO(content), header=header_row) if header_row != -1 else pd.DataFrame()
    except: return pd.DataFrame()

def get_fuhhwa_aggressive(url):
    print(f"ğŸ¤– å•Ÿå‹• Chrome å‰å¾€å¾©è¯å®˜ç¶²: {url}")
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    driver = None
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.get(url)
        time.sleep(8)
        
        max_clicks = 10
        click_count = 0
        while click_count < max_clicks:
            try:
                buttons = driver.find_elements(By.XPATH, "//*[contains(text(),'æ›´å¤š') or contains(text(),'å…¨éƒ¨') or contains(text(),'æŸ¥é–±')]")
                clicked = False
                for btn in buttons:
                    if btn.is_displayed():
                        driver.execute_script("arguments[0].scrollIntoView(true);", btn)
                        time.sleep(1)
                        driver.execute_script("arguments[0].click();", btn)
                        time.sleep(3)
                        clicked = True
                        click_count += 1
                        break
                if not clicked: break
            except: break

        dfs = pd.read_html(driver.page_source)
        best_df = pd.DataFrame()
        max_rows = 0
        for temp in dfs:
            if len(temp) > max_rows and len(temp.columns) >= 3:
                max_rows = len(temp)
                best_df = temp
        return best_df
    except Exception as e:
        print(f"âŒ å¾©è¯çˆ¬èŸ²å¤±æ•—: {e}")
        return pd.DataFrame()
    finally:
        if driver: driver.quit()

def get_etf_data(etf_code):
    df = pd.DataFrame()
    if etf_code == "00981A":
        roc_date = get_roc_date_string(0)
        url = f"https://www.ezmoney.com.tw/ETF/Transaction/PCFExcelNPOI?fundCode=49YTW&date={roc_date}&specificDate=false"
        print(f"ğŸ“¥ ä¸‹è¼‰çµ±ä¸€ (00981A): {url}")
        try:
            res = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
            df = smart_read_excel(res.content)
            if df.empty:
                roc_date_yest = get_roc_date_string(-1)
                url_yest = f"https://www.ezmoney.com.tw/ETF/Transaction/PCFExcelNPOI?fundCode=49YTW&date={roc_date_yest}&specificDate=false"
                res = requests.get(url_yest, headers={"User-Agent": "Mozilla/5.0"})
                df = smart_read_excel(res.content)
        except Exception as e: print(f"âŒ çµ±ä¸€å¤±æ•—: {e}")

    elif etf_code == "00991A":
        url = "https://www.fhtrust.com.tw/ETF/etf_detail/ETF23#stockhold"
        df = get_fuhhwa_aggressive(url)

    return standardize_df(df, source_name=etf_code)

def process_etf(etf_code, etf_name):
    print(f"\n--- è™•ç† {etf_name} ({etf_code}) ---")
    
    file_path = f'data/{etf_code}_history.csv'
    
    # è‡ªå‹•ä¿®å¾©
    if os.path.exists(file_path):
        try:
            check_df = pd.read_csv(file_path)
            if 'æ¬Šé‡' not in check_df.columns:
                os.remove(file_path)
            elif not check_df.empty and 'æ¬Šé‡' in check_df.columns and check_df['æ¬Šé‡'].sum() == 0:
                os.remove(file_path)
        except: pass

    # 1. æŠ“å–ä»Šæ—¥
    df_new = get_etf_data(etf_code)
    
    if df_new.empty: 
        print(f"âš ï¸ ç„¡æ³•ç²å–æ•¸æ“šï¼Œè·³éã€‚")
        return f"âš ï¸ {etf_name} ç„¡æ³•ç²å–æ•¸æ“š"
    
    today_str = datetime.now().strftime('%Y-%m-%d')
    if 'è‚¡ç¥¨ä»£è™Ÿ' in df_new.columns:
        df_new['è‚¡ç¥¨ä»£è™Ÿ'] = df_new['è‚¡ç¥¨ä»£è™Ÿ'].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)
    df_new['Date'] = today_str

    # 2. åˆä½µèˆ‡å»é‡
    if os.path.exists(file_path):
        try:
            old_df = pd.read_csv(file_path, dtype=str)
            final_df = pd.concat([df_new, old_df], ignore_index=True)
            final_df = final_df.drop_duplicates(subset=['Date', 'è‚¡ç¥¨ä»£è™Ÿ'], keep='first')
        except:
            final_df = df_new
    else:
        final_df = df_new

    # 3. å­˜æª”
    final_df.to_csv(file_path, index=False, encoding='utf-8-sig')
    
    # â˜…â˜…â˜… 4. ç”Ÿæˆæˆ°å ± (Analysis) â˜…â˜…â˜…
    report = generate_daily_report(final_df)
    
    return f"âœ… **{etf_name}** æ›´æ–°æˆåŠŸ{report}\n"

def main():
    if not os.path.exists('data'): os.makedirs('data')
    
    msg = ""
    msg += process_etf("00981A", "ä¸»å‹•çµ±ä¸€")
    msg += "\n--------------------\n"
    msg += process_etf("00991A", "ä¸»å‹•å¾©è¯æœªä¾†")
    
    print(msg)
    
    # ç™¼é€ Discord é€šçŸ¥
    send_discord_notify(msg)

if __name__ == "__main__":
    main()
